{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## packages \n",
    "from __future__ import division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix # for sparse matrix\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score # for evaluating results\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path and file name \n",
    "path = 'data/'\n",
    "train_data_fn = 'train-features.txt'\n",
    "test_data_fn = 'test-features.txt'\n",
    "train_label_fn = 'train-labels.txt'\n",
    "test_label_fn = 'test-labels.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "The dataset is split into two subsets: a 700-email subset for training and a 260-email subset for testing. Each of the training and testing subsets contain 50% spam messages and 50% nonspam messages. Additionally, the emails have been preprocessed in the following ways:\n",
    "\n",
    "**1. Stop word removal:** Certain words like \"and,\" \"the,\" and \"of,\" are very common in all English sentences and are not very meaningful in deciding spam/nonspam status, so these words have been removed from the emails.\n",
    "\n",
    "**2. Lemmatization:** Words that have the same meaning but different endings have been adjusted so that they all have the same form. For example, \"include\", \"includes,\" and \"included,\" would all be represented as \"include.\" All words in the email body have also been converted to lower case.\n",
    "\n",
    "**3. Removal of non-words:** Numbers and punctuation have both been removed. All white spaces (tabs, newlines, spaces) have all been trimmed to a single space character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick number of words (a dictionary for this model) is 2500 - most frequent words\n",
    "nwords = 2500 \n",
    "\n",
    "def read_data(data_fn, label_fn):\n",
    "    ## read label_fn\n",
    "    with open(path + label_fn) as f:\n",
    "        content = f.readlines()\n",
    "    label = [int(x.strip()) for x in content]\n",
    "\n",
    "    ## read data_fn\n",
    "    with open(path + data_fn) as f:\n",
    "        content = f.readlines()\n",
    "        \n",
    "    # remove '\\n' at the end of each line\n",
    "    content = [x.strip() for x in content] \n",
    "\n",
    "    dat = np.zeros((len(content), 3), dtype = int)\n",
    "    \n",
    "    for i, line in enumerate(content): \n",
    "        a = line.split(' ')\n",
    "        dat[i, :] = np.array([int(a[0]), int(a[1]), int(a[2])])\n",
    "\n",
    "    # for more information about coo_matrix function         \n",
    "    # https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html\n",
    "    \n",
    "    data = coo_matrix((dat[:, 2], (dat[:, 0] - 1, dat[:, 1] - 1)),\\\n",
    "             shape=(len(label), nwords))\n",
    "    return (data, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use MultinomialNB model\n",
    "Train the model on the training set and predict the spam/nonspam classification on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size = 400, accuracy = 97.6923%\n"
     ]
    }
   ],
   "source": [
    "train_data_fn = 'train-features-400.txt'\n",
    "train_label_fn = 'train-labels-400.txt'\n",
    "test_data_fn = 'test-features.txt'\n",
    "test_label_fn = 'test-labels.txt'\n",
    "\n",
    "(train_data, train_label)  = read_data(train_data_fn, train_label_fn)\n",
    "(test_data, test_label)  = read_data(test_data_fn, test_label_fn)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_data, train_label)\n",
    "\n",
    "y_pred = clf.predict(test_data)\n",
    "print('Training size = %d, accuracy = %.4f%%' % \\\n",
    "      (train_data.shape[0],accuracy_score(test_label, y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       130\n",
      "           1       0.98      0.97      0.98       130\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       260\n",
      "   macro avg       0.98      0.98      0.98       260\n",
      "weighted avg       0.98      0.98      0.98       260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_label, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[128,   2],\n",
       "       [  4, 126]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_label, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smaller training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size = 100, accuracy = 97.6923%\n"
     ]
    }
   ],
   "source": [
    "train_data_fn = 'train-features-100.txt'\n",
    "train_label_fn = 'train-labels-100.txt'\n",
    "test_data_fn = 'test-features.txt'\n",
    "test_label_fn = 'test-labels.txt'\n",
    "\n",
    "(train_data, train_label)  = read_data(train_data_fn, train_label_fn)\n",
    "(test_data, test_label)  = read_data(test_data_fn, test_label_fn)\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_data, train_label)\n",
    "y_pred = clf.predict(test_data)\n",
    "print('Training size = %d, accuracy = %.4f%%' % \\\n",
    "      (train_data.shape[0],accuracy_score(test_label, y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[127,   3],\n",
       "       [  3, 127]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_label, y_pred,labels=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 50 emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size = 50, accuracy = 97.3077%\n"
     ]
    }
   ],
   "source": [
    "train_data_fn = 'train-features-50.txt'\n",
    "train_label_fn = 'train-labels-50.txt'\n",
    "test_data_fn = 'test-features.txt'\n",
    "test_label_fn = 'test-labels.txt'\n",
    "\n",
    "(train_data, train_label)  = read_data(train_data_fn, train_label_fn)\n",
    "(test_data, test_label)  = read_data(test_data_fn, test_label_fn)\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_data, train_label)\n",
    "y_pred = clf.predict(test_data)\n",
    "print('Training size = %d, accuracy = %.4f%%' % \\\n",
    "      (train_data.shape[0],accuracy_score(test_label, y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[126,   4],\n",
       "       [  3, 127]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_label, y_pred,labels=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The errors on the smaller training sets.\n",
    "How many documents did you misclassify? \n",
    "- 50 training documents: 7 misclassified, 2.7%.\n",
    "- 100 training documents: 6 misclassified, 2.3%.\n",
    "- 400 training documents: 6 misclassified, 2.3%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size = 50, accuracy = 69.62%\n"
     ]
    }
   ],
   "source": [
    "clf = BernoulliNB(binarize = .5)\n",
    "clf.fit(train_data, train_label)\n",
    "y_pred = clf.predict(test_data)\n",
    "print('Training size = %d, accuracy = %.2f%%' % \\\n",
    "      (train_data.shape[0],accuracy_score(test_label, y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[125,   5],\n",
       "       [ 74,  56]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_label, y_pred,labels=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> In this problem, MultinomialNB model is better than BernoulliNB model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
